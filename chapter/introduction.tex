\section{Introduction}
Humans have always communicated (\cite{tomasello2010origins}). Over the centuries, this communication evolved and became more complicated. What began with hand gestures evolved into myriads of spoken and written languages.

At the same time, the target audience of communication grew. From small, tight-knit communities, to larger ones, to one-sided mass media communication which allows single actors to reach millions of people (\cite{luhmann1995realitat}). In the mid-2000s, yet another form of communication emerged. Social networks combine traditional, multi-sided communication with the range of mass media and change the way people communicate with each other: Behavioral patterns that were formerly mostly seen in celebrities are now adopted in regular interpersonal communication on social media sites (\cite{stefanoneRelationshipTraditionalMass2010}).

This newly opened communication empowered people to look up information for themselves, rather than having to rely on a single expert in their community. However, low quality-information is widely spread across the internet. This misinformation can lead to skepticism towards scientifically proven concepts (\cite{krimskyRiskCommunicationInternet2007}). One famous example of this is the wide-spread misinformation that vaccines cause autism---a myth that has been debunked multiple times, but is still spread via the internet (\cite{baker2008mercury}).

The often outrageous nature of these kinds of content drives engagement: one study showed that anti-vaccine contents got retweeted 4 times as often as neutral tweets about vaccinations (\cite{blankenshipSentimentContentsRetweets2018}). As the big players on the Internet---Google, Facebook, and Twitter---make money off of this engagement, they want users to see as many engagement-driving contents as possible. This leads to recommendation algorithms that show these contents again and again to people susceptible to this kind of (mis-)information.

This leads to the so-called \emph{filter bubble-effect}. The opinion a user already has gets enforced (\cite{pariser2011filter}), while opposing facts or opinions are less visible. This can lead to social problems: Discussions become less diverse and people think they are part of the majority, even if they are part of a loud minority (\cite{moscoviciSilentMajoritiesLoud1991}).

As of now, social networks do not offer a transparent look into their recommender algorithms. This means that users cannot be sure whether their opinion is shared by a majority. One way to fight this problem is Big Data (\cite{crawfordCriticalQuestionsBig2012}).

As its name suggests, Big Data relies on huge datasets to give meaningful results and insights. Generating these data sets manually is a virtually impossible challenge. However, Twitter allows the automated collection of tweets via their APIs. This means that data collection can run fully automated over a prolonged time. Leveraging such a data set could give user's a bird's-eye view of the social network so that they could see for themselves how certain discussions are unfolding. For this, data visualizations play a big role, as they can help to make huge data sets accessible to laymen (\cite{donalekImmersiveCollaborativeData2014}).

This thesis aims to answer two questions:

\begin{enumerate}
    \item Is it possible to automatically collect all German-language tweets about a specific topic, and store these tweets in a way that they can be analyzed?
    \item Can this data be processed and visualized so that laymen can gain insight from this data?
\end{enumerate}

For this, an app that automatically collects tweets about the currently ongoing Corona epidemic was written. Then, interactive data visualizations for this data were coded. Lastly, these visualizations were tested with laymen who had little to no experience working with Big Data sets.
