\section{Introduction}
"We also hope it might change your mind about what journalism could look like. We believe journalism doesnâ€™t always have to be a one-way conversation in which we present words for you to read. We also want to give you the tools to hold institutions in your life accountable for their choices." (\cite{angwinMakingPrivacyPersonal2020}) -> use this as explanation/motivation

Structure
\begin{itemize}
    \item humans have always communicated
    \item over the centuries, communication grew. From small, tight-knit communities, to larger communities, to one-sided mass-media communication, to globe-spanning social networks, allowing everyone with internet access to communicate with each other in real-time
    \item This opened communication empowered people to look up information for themselves, rather than having to rely on a single expert in their community. However, the internet is riddled with information with bad quality. This can lead to scepticism towards scientifically proven concepts and spread misinformation (\cite{krimskyRiskCommunicationInternet2007}).
    \item This, combined with the filter bubble-effect which enforces the opinion a user already has (\cite{pariser2011filter}), can lead to social problems. Discussions can become less diverse and everyone thinks they are right.
    \item Currently, there is no way to find out reliably what Twitter users think inside of Twitter. One way to battle this problem is Big Data (\cite{crawfordCriticalQuestionsBig2012}). Using this approach could give users a birds-eye view of the network instead of a tailored experience created by recommendation algorithms.
    \item Twitter allows automated collection of tweets via their APIs. This means that collection can run fully-automated over a prolonged period of time. This, however, generates a huge data set that is virtually impossible to manually analyze and tag
    \item Natural Language Processing can help to summarize these tweets in a way that makes manual coding of every tweet obsolete
    \item A good way to make such big data sets accessible to laymen is data visualization (\cite{donalekImmersiveCollaborativeData2014}). This, in combination with NLP, can help users to understand the data set on a meta-level, and not on the level of the individual tweets.
\end{itemize}

The goal of this thesis is two-fold: is it possible to automatically collect all German tweets to a specific topic and store them in a way that they can be analyzed? And can this data be processed and visualized in a way that allows laymen to gather information from this data?