\section{Method reflection}
This section will discuss the methods used for this master thesis. While the results are generally convincing, there is still room for improvement in further studies.

\subsection*{Mayring did not accurately reflect this study's goals}
One of the biggest issues for the author of this study is that the focus of the study and the focus of this written-out thesis do not fully overlap. The study began as a feasibility analysis that aimed to find out if it is possible to collect large amounts of tweets and show them in such a way that laymen can interpret the data. In this initial state, the study consisted of two parts:

\begin{enumerate}
    \item The automated collection and storage of every German tweet to a specific topic---in this case, tweets related to the Coronavirus,
    \item and an easily accessible visualization of these tweets which can give insight to people who are laymen when it comes to analyzing big data
\end{enumerate}

The study's goal was to test several approaches on how to implement these two parts. To evaluate the outcome of this study from a communications science-perspective, an additional interview study based on Mayring's approach to qualitative content analysis was conducted. The results reported in this thesis are mostly based on the findings of this interview study. This means that the results presented in this study, while generating additional insights, do not accurately reflect the work that went into making this thesis. Focusing on the qualitative content analysis gave insights on what laymen expect from a data visualization and what helps them to analyze data. It did not answer the questions if the method to collect and store the tweets and to visualize the data set were appropriate.

\subsection*{Streaming API made it impossible to take Likes into account}
One of the possible problems of collecting the data the way they were collected is that Likes could not be taken into account for the analysis of the tweets. Studies have shown that likes are strongly linked to actual engagement and support, e.g., during congressional elections (\cite{macwilliamsForecastingCongressionalElections2015}). This hints at the importance of likes to measure the general public's approval of specific tweets. In the current implementation, the volume of the tweets strongly affects the sentiment analysis: if many negative tweets are sent on a specific day, the overall sentiment on that day will go down. This holds true the other way around as well. Many positive tweets affect the curve so that the daily average goes up.

This means that, in theory, a bot army could flood specific topics with very negative tweets. Even if not a single person saw these tweets, or interacted with them, these tweets would affect the reported overall sentiment. If the likes of a tweet could be collected as well, users could, e.g., filter for tweets with at least 5 likes. This would filter filter out the tweets which did not drive engagement on Twitter.

On the other hand, this approach would bring additional problems:
\begin{itemize}
    \item Tweets from smaller accounts would be filtered out, even though these accounts are not necessarily part of a bot network.
    \item Filtering out tweets that have less than an arbitrary number of likes distorts the data set in some way. While they might paint a more accurate picture of what society thinks by filtering out automated, nearly invisible tweets, this could also silence the influence of people without celebrity or influencer status. Seeing that Twitter is a grassroots medium that allows people to make their voices heard regardless of their social status (\cite{passmann2019alte}), a carelessly implemented filter option could silence those voices.
    \item Collecting a tweet's likes requires either the usage of the archive API or a script that fetches the likes of a tweet a specific time after it was collected, e.g., three days after initial collection. This is necessary because the streaming API sends a tweet to the collecting script almost immediately after it was sent. This means that every time the streaming API sends a tweet, its number of likes should be 0.
\end{itemize}

Future studies could focus on addressing these issues and finding a way to make the dataset, on the one hand, more reliable---e.g., by filtering out bots---while on the other hand keeping the open culture of Twitter in mind and not silencing the voices of everyday people.

\begin{itemize}
    %\item Streaming API was the better option on the free tier. But this solution is not flexible enough to see how different topics get discussed on Twitter: the data collection ran over 2 months, and this might not be feasible. (braucht eigentlich nicht mehr gemacht werden)
    \item Accessibility Issues: too much reliance on colors alone. It would have been better to also include texture patterns. Both color and patterns are qualitative nominal variables, so they can encode the same information (\cite[1860]{bornerDataVisualizationLiteracy2019}).
    \item Using \emph{Shape Up} to plan the development of the tool worked well. It is possible, however, that the clear distinction pipeline---d3-visualizations---writing the thesis meant that some parts of the study, like the pipeline, took more time than necessary.
    \item The participants in the interview study were mostly students. This was partly because of the ongoing Covid-19 pandemic, which made it necessary to use online conferencing software to recruit the participants and conduct the interviews with them. Face-to-face interviews with a more diverse group of participants can yield further results. This should be considered for future studies.
    \item Using Observable sped up the development process and was the right choice for the prototype. For a final product, however, the limitations of Observable are too severe, especially when using databases. Notebooks with databases require permissions to be set up, and for this users need to create an Observable account and join the team workspace where the notebook is located. Instead of using Observable, users should be able to use a web tool without logging in. One example of a data analysis tool on the web is \emph{Blacklight}\footnote{https://themarkup.org/blacklight/}, where users can scan other web pages for trackers.
    %\item Likes were not taken into account, which might is a problem in two ways: Likes also raise the visibility of a tweet in a network, and they are an indicator of how many people saw and interacted with the post. For example, bot networks without any followers may send a large number of tweets that almost no one ever sees as these tweets are not liked, retweeted, or seen by followers. These tweets would still be visible in the visualizations. Future studies could look into ways how to make the visualizations more reliable, for example by taking further metrics like Likes into account.
    %\item The study started began as a feasibility study: is it possible to collect large amounts of tweets and show them in a way that laymen can interpret the data and want to? However, due to the chosen method---qualitative interviews, coded based on Mayring's approach---the focus of this written thesis is less the question if such a collection is feasible or not, but rather what participants need in visualizations. While this study generated insight, using Mayring did not answer the question if the methods used to collect the data and code the visualizations were appropriate. 
\end{itemize}
